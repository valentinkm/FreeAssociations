#!/usr/bin/env python3
"""
run_lm.py ‚Äì robust generator of TOTAL_SETS free associations per cue
"""
import time
import json, textwrap, random, re, datetime as dt
from math import ceil
from pathlib import Path
from json.decoder import JSONDecodeError

import pandas as pd
from openai import OpenAI

from .settings import CFG, TOTAL_SETS, MAX_TOKENS, DATA_PATH
from .prompt_loader import render_prompt, TEMPLATES, FUNC_SCHEMA

client = OpenAI()

# ‚îÄ‚îÄ helpers ---------------------------------------------------------------
def _log_prompt(cue, n_sets, prompt):
    print(f"\nüü¶ PROMPT | cue={cue!r} n_sets={n_sets}\n"
          + textwrap.indent(prompt, "   "))

def _log_reply(txt):
    if not txt:
        print("üü• REPLY  | <None>")
    else:
        print(f"üü© REPLY  | {' '.join(txt.split())[:200]}‚Ä¶")

def _repair_json(txt):
    if not txt:
        return None
    m = re.search(r'\]\s*\}', txt)
    if m:
        candidate = txt[:m.end()]
        try:
            json.loads(candidate)
            return candidate
        except JSONDecodeError:
            pass
    return None

# ‚îÄ‚îÄ single call with retries ---------------------------------------------
def call_model(cue: str, n_sets: int, prompt_key: str, retry=False):
    user_msg = render_prompt(TEMPLATES[prompt_key], cue, n_sets)
    _log_prompt(cue, n_sets, user_msg)

    msgs = [
        {"role": "system", "content": "Return ONLY valid JSON."},
        {"role": "user",   "content": user_msg},
    ]
    kw = dict(
        model=CFG["model"],
        temperature=CFG["temperature"],
        top_p=CFG["top_p"],
        frequency_penalty=CFG["frequency_penalty"],
        presence_penalty=CFG["presence_penalty"],
        max_tokens=MAX_TOKENS,
        messages=msgs,
        response_format={"type": "json_object"},  # nudge to JSON
    )
    if prompt_key == "chatml_func":
        kw["functions"] = [FUNC_SCHEMA(n_sets)]

    rsp = client.chat.completions.create(**kw)
    if not rsp.choices:
        if not retry:
            print("‚ö†Ô∏è  Empty choices ‚Äì retrying once")
            return call_model(cue, n_sets, prompt_key, retry=True)
        raise RuntimeError("OpenAI returned no choices twice.")

    choice = rsp.choices[0]
    raw = (choice.message.function_call.arguments
           if choice.finish_reason == "function_call"
           else choice.message.content)
    _log_reply(raw)

    # ---------- if raw is None or '', escalate ----------
    if not raw:
        if prompt_key != "chatml_func" and not retry:
            print("‚ö†Ô∏è  Empty payload ‚Äì retrying via function_call")
            return call_model(cue, n_sets, "chatml_func", retry=True)
        raise RuntimeError("Received empty payload twice.")

    # ---------- parse / repair / fallback ---------------
    try:
        return json.loads(raw)["sets"][:n_sets]
    except JSONDecodeError:
        repaired = _repair_json(raw)
        if repaired:
            return json.loads(repaired)["sets"][:n_sets]
        if prompt_key != "chatml_func" and not retry:
            print("‚ö†Ô∏è  Parse failed ‚Äì retrying via function_call")
            return call_model(cue, n_sets, "chatml_func", retry=True)
        raise

# ‚îÄ‚îÄ outer loop -----------------------------------------------------------
def generate_and_save(out_path: str, seed: int | None = None):
    if seed is not None:
        random.seed(seed)

    print(f"üü¢ Writing data to {out_path}")
    cues = pd.read_csv(DATA_PATH)["cue"].dropna().unique()
    sample = random.sample(list(cues), k=CFG["num_cues"])

    single = CFG["calls_per_cue"] == 1
    prompt_key = "human_single" if single else CFG["prompt"]
    chunk = 1 if single else CFG["calls_per_cue"]
    chunks = ceil(TOTAL_SETS / chunk)

    with open(out_path, "w", encoding="utf-8") as fw:
        for cue in sample:
            sets_acc = []
            while len(sets_acc) < TOTAL_SETS:
                batch = min(chunk, TOTAL_SETS - len(sets_acc))
                try:
                    sets_acc.extend(call_model(cue, batch, prompt_key))
                except RuntimeError as e:
                    # empty payload twice ‚Äì back‚Äëoff and retry once
                    print(f"‚ö†Ô∏è  {cue}: {e}  ‚Äì waiting 2‚ÄØs then retrying once")
                    time.sleep(2)
                    try:
                        sets_acc.extend(call_model(cue, batch, prompt_key, retry=True))
                    except RuntimeError:
                        print(f"‚è≠Ô∏è  Skipping cue '{cue}' after repeated empty payloads")
                        break   # move on to next cue

            if sets_acc:   # only write if we obtained at least one batch
                fw.write(json.dumps({"cue": cue,
                                     "sets": sets_acc,
                                     "cfg":  CFG}) + "\n")

    print(f"‚úÖ Done ‚Äî wrote {len(sample)} cues (some may be skipped) √ó ‚â§{TOTAL_SETS} sets")


# ‚îÄ‚îÄ CLI ------------------------------------------------------------------
if __name__ == "__main__":
    import argparse
    p = argparse.ArgumentParser()
    p.add_argument("outfile", nargs="?", default=None,
                   help="Path for JSONL output")
    p.add_argument("--seed", type=int, default=None,
                   help="Random seed for cue sampling")
    args = p.parse_args()

    out = args.outfile or f"runs/lm_{dt.datetime.now():%Y%m%d_%H%M%S}.jsonl"
    Path(out).parent.mkdir(parents=True, exist_ok=True)
    generate_and_save(out, seed=args.seed)
